{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Particles 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Dataset\n",
    "Pipeline:\n",
    "* Generation of high-res data (reference) using some random cubes of water\n",
    "* Extracting relevant data (particle data and grid data) like e.g. sdf, velocity, pressure, density...\n",
    "* Down-sampling of particles (by a given factor) and generation of the low-res data (source)\n",
    "* Extract corresponding and relevant patches on the surface from the data-set pairs (considering the low-res data)\n",
    "* Use patche-pairs to train the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple structs containing parameters for different data-set and neural network versions.\n",
    "\n",
    "Data-set Parameters:\n",
    "* **prefix**: prefix of filename\n",
    "* **fps**: frames per second, the velocity of the simulation\n",
    "* **frame_count**: count of generated frames\n",
    "* **sub_res**: count of particles per cell (per dimension)\n",
    "* **res**: resolution of high-res grid\n",
    "* **var1**: factor of drop falling in basin data-sets (var0 is 1 - var1 - var2)\n",
    "* **var2**: factor of two drop shooting against other\n",
    "* **factor**: goal up-scale factor of particles\n",
    "* **upres**: specify if the low-res grids will be up-scaled to res (=> input and output same scale)\n",
    "* **seed**: seed for random data-set generation\n",
    "* **min_scale**: minimum scale of boxes for data-set generation\n",
    "* **max_scale**: maximum scale of boxes for data-set generation\n",
    "* **min_pos**: minimum x-position of boxes\n",
    "* **max_pos**: maximum x-position of boxes\n",
    "* **max_h**: maximum start-height of boxes\n",
    "* **max_cnt**: maximum count of boxes\n",
    "* **circ_vel**: velocity used for colliding drops\n",
    "\n",
    "Neural Network Parameters:\n",
    "* **patch_size**: size of generated surface patches (of the low-res data)\n",
    "* **stride**: stride used for the generation of the patches\n",
    "* **surf**: surface tolerance, specifies which sdf-values are considered as surface (for patches)\n",
    "* **l_fac**: multiplicative factor of low-res sdf-patches\n",
    "* **h_fac**: multiplicative factor of high-res sdf-patches\n",
    "* **use_tanh**: apply tanh on sdf-patches, after multiplication with factor\n",
    "* **train_data_count**: count of training data-sets\n",
    "* **val_split**: factor of how much of training data is used for validation\n",
    "* **test_data_count**: count of test data-sets\n",
    "* **t_start**: timestep start-point of data\n",
    "* **t_end**: timestep end-point of data\n",
    "* **features**: list of strings which specifiy which features to use:\n",
    "    * 'sdf': levelset data\n",
    "    * 'vel': velocity data\n",
    "    * 'dens': density data\n",
    "    * 'pres': pressure data\n",
    "* **batch_size**: batch size used for training and validation\n",
    "* **learning_rate**: learing rate used for training\n",
    "* **epochs**: training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DatasetParam:\n",
    "    def __init__(self, prefix=\"sph_2D\", fps=30, frame_count=50, \n",
    "                 sub_res=2, res=150, var1=0, var2=0, \n",
    "                 seed=124820112, min_scale=0.05, max_scale=0.3,\n",
    "                 min_pos=0.2,max_pos=0.8,max_h=0.1,max_cnt=5, circ_vel=100.):\n",
    "    \n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.fps = fps\n",
    "        self.frame_count = frame_count\n",
    "        self.sub_res = sub_res\n",
    "        self.res = res\n",
    "        \n",
    "        self.var1 = var1\n",
    "        self.var2 = var2\n",
    "\n",
    "        self.seed = seed\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.min_pos = min_pos\n",
    "        self.max_pos = max_pos\n",
    "        self.max_h = max_h\n",
    "        self.max_cnt = max_cnt    \n",
    "        self.circ_vel = circ_vel\n",
    "\n",
    "        \n",
    "class PreParam:\n",
    "    def __init__(self, patch_size=9, stride=3, surf=0.2, l_fac=1.0,h_fac=1.0,use_tanh=0, \n",
    "                 factor=10, upres=1, min_n=0, var=1):\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.surf = surf\n",
    "        \n",
    "        self.l_fac = l_fac\n",
    "        self.h_fac = h_fac\n",
    "        self.use_tanh = use_tanh\n",
    "        \n",
    "        self.factor = factor\n",
    "        self.upres = upres\n",
    "        self.min_n = min_n\n",
    "        self.var = var\n",
    "        \n",
    "    \n",
    "class NNParam:\n",
    "    def __init__(self, train_data_count=5, val_split=0.2, test_data_count=1,\n",
    "                 t_start = 20, t_end = 21, features=['sdf'], \n",
    "                 batch_size=32,learning_rate=1e-3,epochs=1000, residual=False, use_spc=False,\n",
    "                 mse_fac=1., adv_fac=0.):\n",
    "        self.train_data_count = train_data_count\n",
    "        self.val_split = val_split\n",
    "        self.test_data_count = test_data_count\n",
    "        self.t_start = t_start\n",
    "        self.t_end = t_end\n",
    "        self.features = features\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.use_spc = use_spc\n",
    "        self.residual = residual\n",
    "        self.mse_fac = mse_fac\n",
    "        self.adv_fac = adv_fac    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Version:\n",
    "* **V0**: default values, input and output patches same size\n",
    "* **V1**: smaller patches, input and output patches different size, uses simple post-processing of patches\n",
    "* **V2**: different seed, uses different data-set types\n",
    "\n",
    "NN Version:\n",
    "* **V0**: CNN with only sdf data\n",
    "* **V1**: also velocity as input\n",
    "* **V2**: 'Subpixel Convolution' instead of 'Transposed Convolution'\n",
    "\n",
    "Combi Version:\n",
    "Different combinations of data versions and NN versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_version_param = [\n",
    "    DatasetParam(),\n",
    "    DatasetParam(seed=123412144,\n",
    "                 var1=1./3,\n",
    "                 var2=1./3),\n",
    "    DatasetParam(seed=123412144,\n",
    "                var1=0.5,\n",
    "                frame_count=20)\n",
    "]\n",
    "\n",
    "pre_version_param = [\n",
    "    PreParam(),\n",
    "    PreParam(upres=0,\n",
    "            stride=2,\n",
    "            surf=0.5,\n",
    "            factor=9,\n",
    "            patch_size=5,\n",
    "            h_fac=4.,\n",
    "            l_fac=12.,\n",
    "            use_tanh=1),\n",
    "    PreParam(upres=0,\n",
    "            stride=2,\n",
    "            surf=0.5,\n",
    "            factor=9,\n",
    "            patch_size=5,\n",
    "            h_fac=4.,\n",
    "            l_fac=12.,\n",
    "            use_tanh=1,\n",
    "            min_n=3,\n",
    "            var=5),\n",
    "    PreParam(upres=0,\n",
    "            stride=2,\n",
    "            surf=0.5,\n",
    "            factor=9,\n",
    "            patch_size=5,\n",
    "            h_fac=4.,\n",
    "            l_fac=12.,\n",
    "            use_tanh=1,\n",
    "            min_n=3),\n",
    "    PreParam(upres=0,\n",
    "            stride=2,\n",
    "            surf=0.5,\n",
    "            factor=9,\n",
    "            patch_size=5,\n",
    "            h_fac=4.,\n",
    "            l_fac=12.,\n",
    "            use_tanh=1,\n",
    "            var=5)\n",
    "]\n",
    "\n",
    "nn_version_param = [\n",
    "    NNParam(),\n",
    "    NNParam(train_data_count=9, \n",
    "            test_data_count=1, \n",
    "            t_start=5,\n",
    "            t_end=15,\n",
    "            epochs=250,\n",
    "            features=['sdf','vel'],\n",
    "            use_spc=True),\n",
    "    NNParam(train_data_count=9, \n",
    "            test_data_count=3, \n",
    "            t_start=5,\n",
    "            t_end=15,\n",
    "            epochs=250,\n",
    "            features=['sdf','vel'],\n",
    "            use_spc=True,\n",
    "            residual=True),\n",
    "    NNParam(train_data_count=18, \n",
    "            test_data_count=2, \n",
    "            val_split=0.2,\n",
    "            t_start=5,\n",
    "            t_end=15,\n",
    "            epochs=250,\n",
    "            features=['sdf','vel'],\n",
    "            use_spc=True,\n",
    "            residual=True),\n",
    "    NNParam(train_data_count=18, \n",
    "            test_data_count=2, \n",
    "            val_split=0.2,\n",
    "            t_start=5,\n",
    "            t_end=15,\n",
    "            epochs=250,\n",
    "            features=['sdf','vel'],\n",
    "            use_spc=True,\n",
    "            residual=True,\n",
    "            mse_fac=1.0,\n",
    "            adv_fac=0.1)\n",
    "]\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Combi_Tuple = namedtuple('Combi_Tuple', ['data','pre','nn'])\n",
    "version_combi_param = [\n",
    "    Combi_Tuple(0,0,0), #0\n",
    "    Combi_Tuple(1,0,1),\n",
    "    Combi_Tuple(1,1,1),\n",
    "    Combi_Tuple(1,1,2),\n",
    "    Combi_Tuple(2,1,3),\n",
    "    Combi_Tuple(2,2,3), #5\n",
    "    Combi_Tuple(2,3,3),\n",
    "    Combi_Tuple(2,4,3),\n",
    "    Combi_Tuple(2,1,4),\n",
    "    Combi_Tuple(2,4,4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"2D_SPH/scenes/tools\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "manta_loc = \"2D_SPH/\"\n",
    "\n",
    "version = 8\n",
    "version_combi = version_combi_param[version]\n",
    "data_param = data_version_param[version_combi.data]\n",
    "pre_param = pre_version_param[version_combi.pre]\n",
    "nn_param = nn_version_param[version_combi.nn]\n",
    "\n",
    "data_loc = \"2D_data/\"\n",
    "src = \"lowres\"\n",
    "ref = \"highres\"\n",
    "\n",
    "# count of training/validation setups\n",
    "data_count = nn_param.train_data_count + nn_param.test_data_count\n",
    "\n",
    "verbose = False\n",
    "\n",
    "def create_curr_date_folder(path):\n",
    "    now = datetime.datetime.now()\n",
    "    path += \"%04d%02d%02d\"%(now.year,now.month,now.day)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path + \"/\"\n",
    "\n",
    "src_prefix = \"%s%s/%s_v%02d-%02d\" % (data_loc, src, data_param.prefix, version_combi.data, version_combi.pre)\n",
    "ref_prefix = \"%s%s/ref_%s_v%02d\" % (data_loc, ref, data_param.prefix, version_combi.data)\n",
    "test_prefix = \"%stest/%s_v%02d\" % (data_loc, data_param.prefix, version_combi.data)\n",
    "\n",
    "src_patches_path = \"%spatches/%s/%s_v%02d-%02d\" % (data_loc, src, data_param.prefix, version_combi.data, version_combi.pre)\n",
    "ref_patches_path = \"%spatches/%s/ref_%s_v%02d-%02d\" % (data_loc, ref, data_param.prefix, version_combi.data, version_combi.pre)\n",
    "\n",
    "\n",
    "def run_manta(scene, param={},logfile=\"\"):\n",
    "    command = [manta_loc+\"build/manta\", manta_loc+scene]\n",
    "\n",
    "    for k, v in param.items():\n",
    "        command += [k, str(v)]\n",
    "        \n",
    "    if logfile != \"\":\n",
    "        command += [\">\",logfile]\n",
    "        command += [\"; echo\", \"output written into %s\" % logfile]\n",
    "        \n",
    "    print(\" \".join(command) + \"\\n\")\n",
    "\n",
    "    proc = Popen(command, stdin=None, stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "    if verbose:\n",
    "        for line in proc.stdout:\n",
    "            print(line.decode('utf-8'))\n",
    "    for line in proc.stderr:\n",
    "        print(line.decode('utf-8'))\n",
    "        \n",
    "def manta_script(path):\n",
    "    return manta_loc+\"build/manta \" + manta_loc + path\n",
    "        \n",
    "class ShellScript:\n",
    "    def __init__(self,path,prefix=\"\"):\n",
    "        self.path = path\n",
    "        self.prefix = prefix\n",
    "        self.clear()\n",
    "        \n",
    "    def clear(self):\n",
    "        self.text = \"#!/bin/sh\\n\"\n",
    "    \n",
    "    def add_line(self,cmd):\n",
    "        self.text += \"%s %s\\n\" % (self.prefix, cmd)\n",
    "    \n",
    "    def add_param(self,param):\n",
    "        l = [self.prefix]\n",
    "        for k,v in param.items():\n",
    "            l += [k, str(v)]\n",
    "        self.text += \" \".join(l) + \"\\n\"\n",
    "        \n",
    "    def write(self):\n",
    "        with open(self.path, 'w') as f:\n",
    "            f.write(self.text)\n",
    "            \n",
    "        print(\"Shell Script generated: \" + self.path)\n",
    "        \n",
    "        proc = Popen([\"chmod\",\"+x\",self.path], stdin=None, stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "        if verbose:\n",
    "            for line in proc.stdout:\n",
    "                print(line.decode('utf-8'))\n",
    "        for line in proc.stderr:\n",
    "            print(line.decode('utf-8'))\n",
    "            \n",
    "    def execute(self):\n",
    "        proc = Popen(\"./\"+self.path, stdin=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Script generated: setup_dirs.sh\n",
      "Shell Script generated: complete_sph_2D_v08.sh\n",
      "Execute Script for data generation and training: complete_sph_2D_v08.sh\n",
      "Shell Script generated: clean_sph_2D_v08.sh\n",
      "Execute Script to remove generated data: clean_sph_2D_v08.sh\n"
     ]
    }
   ],
   "source": [
    "p = \"setup_dirs.sh\"\n",
    "\n",
    "setup_dir_script = ShellScript(p, \"mkdir -p\")\n",
    "setup_dir_script.add_line(data_loc)\n",
    "setup_dir_script.add_line(data_loc+src)\n",
    "setup_dir_script.add_line(data_loc+ref)\n",
    "setup_dir_script.add_line(data_loc+\"log\")\n",
    "setup_dir_script.add_line(\"models/\"+data_loc)\n",
    "setup_dir_script.add_line(data_loc+\"patches\")\n",
    "setup_dir_script.add_line(data_loc+\"patches/\"+src)\n",
    "setup_dir_script.add_line(data_loc+\"patches/\"+ref)\n",
    "setup_dir_script.add_line(data_loc+\"result\")\n",
    "setup_dir_script.add_line(data_loc+\"test\")\n",
    "setup_dir_script.add_line(data_loc+\"screenshots\")\n",
    "\n",
    "setup_dir_script.write()\n",
    "\n",
    "setup_dir_script.execute()\n",
    "\n",
    "script_paths = {\n",
    "    \"ref_gen\" : \"gen_ref_%s_v%02d.sh\" % (data_param.prefix, version_combi.data),\n",
    "    \"src_gen\" : \"gen_src_%s_v%02d-%02d.sh\" % (data_param.prefix, version_combi.data, version_combi.pre),\n",
    "    \"patch_gen\" : \"gen_patches_%s_v%02d-%02d.sh\" % (data_param.prefix, version_combi.data, version_combi.pre),\n",
    "    \"train\" : \"train_%s_v%02d.sh\" % (data_param.prefix, version)\n",
    "}\n",
    "\n",
    "p = \"complete_%s_v%02d.sh\" % (data_param.prefix, version)\n",
    "complete_script = ShellScript(p)\n",
    "complete_script.add_line(\"./\"+script_paths['ref_gen'])\n",
    "complete_script.add_line(\"./\"+script_paths['src_gen'])\n",
    "complete_script.add_line(\"./\"+script_paths['patch_gen'])\n",
    "complete_script.add_line(\"./\"+script_paths['train'])\n",
    "complete_script.write()\n",
    "\n",
    "print(\"Execute Script for data generation and training: \" + p)\n",
    "\n",
    "p = \"clean_%s_v%02d.sh\" % (data_param.prefix, version)\n",
    "clean_script = ShellScript(p, \"rm\")\n",
    "clean_script.add_line(ref_prefix+\"*\")\n",
    "#clean_script.add_line(test_prefix+\"*\")\n",
    "clean_script.add_line(src_prefix+\"*\")\n",
    "clean_script.add_line(src_patches_path+\"*\")\n",
    "clean_script.add_line(ref_patches_path+\"*\")\n",
    "clean_script.write()\n",
    "\n",
    "print(\"Execute Script to remove generated data: \" + p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute 2D down-scale factor:\n",
    "$$lowres=\\frac{res}{\\sqrt(factor)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D factor: 3.000000\n",
      "low resolution: 50\n",
      "big patch size. 15\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "low_res = data_param.res\n",
    "high_patch_size = pre_param.patch_size\n",
    "factor_2D = 1.\n",
    "if not pre_param.upres:\n",
    "    factor_2D = math.sqrt(pre_param.factor)\n",
    "    low_res = int(low_res/factor_2D)\n",
    "    high_patch_size = int(high_patch_size*factor_2D)\n",
    "    \n",
    "print(\"2D factor: %f\" % factor_2D)\n",
    "print(\"low resolution: %d\" % low_res)\n",
    "print(\"big patch size. %d\" % high_patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Script generated: gen_ref_sph_2D_v02.sh\n",
      "Execute Script for reference data generation: gen_ref_sph_2D_v02.sh\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "script = ShellScript(script_paths[\"ref_gen\"], manta_script(\"scenes/2D_sph.py\"))\n",
    "\n",
    "param = {}\n",
    "\n",
    "#disable gui\n",
    "param['gui'] = 0\n",
    "\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "# write only every 30th frame -> 30 frames are one timestep\n",
    "param['fps'] = data_param.fps\n",
    "\n",
    "# simulation time (how many frames)\n",
    "param['t_end'] = float(data_param.frame_count) / data_param.fps\n",
    "\n",
    "# run random training setups\n",
    "random.seed(data_param.seed)\n",
    "\n",
    "def call_dataset_gen(var0,var1,var2,off):\n",
    "    def run_gen(cubes,cnt):\n",
    "        param['c_cnt'] = len(cubes)\n",
    "        \n",
    "        param['res'] = data_param.res\n",
    "        param['out'] = (ref_prefix + \"_d%03d\")%cnt + \"_%03d\"\n",
    "        script.add_param(dict(param, **cubes))\n",
    "        \n",
    "        param['res'] = low_res\n",
    "        param['out'] = (test_prefix + \"_d%03d\")%cnt + \"_%03d\"\n",
    "        script.add_param(dict(param, **cubes))        \n",
    "        \n",
    "    param['circ'] = 0\n",
    "    for i in range(var0):\n",
    "        # generate different cubes with dataformat \"pos_x,pos_y,scale_x,scale_y\"\n",
    "        cubes = {}\n",
    "        for c in range(random.randint(1,data_param.max_cnt)):    \n",
    "            scx = random.uniform(data_param.min_scale, data_param.max_scale)\n",
    "            scy = random.uniform(data_param.min_scale, data_param.max_scale)\n",
    "            px = random.uniform(data_param.min_pos+scx/2, data_param.max_pos-scx/2)\n",
    "            py = random.uniform(0, data_param.max_h) + scy/2\n",
    "            cubes['c%d'%c] = \"%f,%f,%f,%f\"%(px,py,scx,scy)\n",
    "        run_gen(cubes,off)\n",
    "        off+=1\n",
    "        \n",
    "\n",
    "    for i in range(var1):\n",
    "        cubes = {}\n",
    "        scy = data_param.max_h\n",
    "        cubes['c0'] = \"%f,%f,%f,%f\"%(0, scy/2, 1, scy)\n",
    "        for c in range(1,random.randint(2,data_param.max_cnt)):    \n",
    "            scx = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            scy = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            px = random.uniform(data_param.min_pos+scx/2, data_param.max_pos-scx/2)\n",
    "            py = random.uniform(data_param.min_pos+scy/2, data_param.max_pos*0.5-scy/2)\n",
    "            cubes['c%d'%c] = \"%f,%f,%f,%f\"%(px,py,scx,scy)\n",
    "        run_gen(cubes, off)\n",
    "        off+=1\n",
    "\n",
    "    param['circ'] = data_param.circ_vel\n",
    "    for i in range(var2):\n",
    "        cubes = {}\n",
    "        for c in range(random.randint(2,data_param.max_cnt)):    \n",
    "            scx = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            scy = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            px = random.uniform(data_param.min_pos+scx/2, data_param.max_pos-scx/2)\n",
    "            py = random.uniform(data_param.min_pos+scy/2, data_param.max_pos-scy/2)\n",
    "            cubes['c%d'%c] = \"%f,%f,%f,%f\"%(px,py,scx,scy)\n",
    "        run_gen(cubes, off)\n",
    "        off+=1\n",
    "    \n",
    "var1 = int(nn_param.train_data_count * data_param.var1)\n",
    "var2 = int(nn_param.train_data_count * data_param.var2)\n",
    "var0 = nn_param.train_data_count - var1 - var2\n",
    " \n",
    "call_dataset_gen(var0,var1,var2,0)\n",
    "\n",
    "var1 = int(nn_param.test_data_count * data_param.var1)\n",
    "var2 = int(nn_param.test_data_count * data_param.var2)\n",
    "var0 = nn_param.test_data_count - var1 - var2\n",
    "\n",
    "call_dataset_gen(var0,var1,var2,nn_param.train_data_count)\n",
    "\n",
    "script.write()\n",
    "\n",
    "print(\"Execute Script for reference data generation: \" + script_paths[\"ref_gen\"])\n",
    "\n",
    "#script.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Low-res Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Script generated: gen_src_sph_2D_v02-01.sh\n",
      "Execute Script for source data generation: gen_src_sph_2D_v02-01.sh\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "script = ShellScript(script_paths[\"src_gen\"], manta_script(\"scenes/down_scale.py\"))\n",
    "\n",
    "param = {}\n",
    "\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "param['upres'] = pre_param.upres\n",
    " \n",
    "param['factor'] = pre_param.factor\n",
    "param['gui'] = 0\n",
    "param['t'] = data_param.frame_count\n",
    "param['min_n'] = pre_param.min_n\n",
    "\n",
    "random.seed(data_param.seed)\n",
    "\n",
    "for i in range(data_count):\n",
    "    for j in range(pre_param.var):\n",
    "        param['seed'] = random.randint(0,45820438204)\n",
    "        param['in'] = (ref_prefix + \"_d%03d\")%(i) + \"_%03d\"\n",
    "        param['out'] = (src_prefix + \"_d%03d_var%02d\")%(i,j) + \"_%03d\"\n",
    "        script.add_param(param)     \n",
    "        #run_manta(\"scenes/down_scale.py\", param)\n",
    "        \n",
    "script.write()\n",
    "\n",
    "print(\"Execute Script for source data generation: \" + script_paths[\"src_gen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Surface-Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Script generated: gen_patches_sph_2D_v02-01.sh\n",
      "Execute Script for patch generation: gen_patches_sph_2D_v02-01.sh\n"
     ]
    }
   ],
   "source": [
    "script = ShellScript(script_paths[\"patch_gen\"], manta_script(\"scenes/extract_patches.py\"))\n",
    "\n",
    "param = {}\n",
    "\n",
    "param[\"t\"] = data_param.frame_count\n",
    "\n",
    "# patch size\n",
    "param[\"psize\"] = pre_param.patch_size\n",
    "param[\"stride\"] = pre_param.stride\n",
    "\n",
    "param[\"hpsize\"] = high_patch_size\n",
    "\n",
    "param[\"l_fac\"] = pre_param.l_fac\n",
    "param[\"h_fac\"] = pre_param.h_fac\n",
    "param[\"tanh\"] = pre_param.use_tanh\n",
    "\n",
    "# tolerance of surface\n",
    "param[\"surface\"] = pre_param.surf\n",
    "\n",
    "for i in range(data_count):\n",
    "    for j in range(pre_param.var):\n",
    "        param[\"h_in\"] = ref_prefix + \"_d%03d\"%(i) + \"_%03d\"\n",
    "        param[\"l_in\"] = src_prefix + \"_d%03d_var%02d\"%(i,j) + \"_%03d\"\n",
    "        param[\"h_out\"] = ref_patches_path + \"_d%03d_var%02d\"%(i,j) + \"_%03d\"\n",
    "        param[\"l_out\"] = src_patches_path + \"_d%03d_var%02d\"%(i,j) + \"_%03d\"\n",
    "        script.add_param(param)\n",
    "        #run_manta(\"scenes/extract_patches.py\", param)\n",
    "        \n",
    "script.write()\n",
    "print(\"Execute Script for patch generation: \" + script_paths[\"patch_gen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show low-res data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py in 2D_data/lowres/sph_2D_v02-01_d019_var00_%03d_ps.uni res 50 t 20 sdf 2D_data/lowres/sph_2D_v02-01_d019_var00_%03d_sdf.uni\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 19\n",
    "var = 0\n",
    "\n",
    "# show low res\n",
    "param['in'] = src_prefix + \"_d%03d_var%02d\"%(dataset,var) + \"_%03d_ps.uni\"\n",
    "param['sdf'] = src_prefix + \"_d%03d_var%02d\"%(dataset,var) + \"_%03d_sdf.uni\"\n",
    "param['t'] = data_param.frame_count\n",
    "param['res'] = low_res\n",
    "\n",
    "#param['scr'] = #create_curr_date_folder(data_loc+'screenshots/') + \"sph_%03d_sdf.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show real low-res data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py in 2D_data/test/sph_2D_v02_d019_%03d_ps.uni res 50 t 20 sdf 2D_data/test/sph_2D_v02_d019_%03d_sdf.uni\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 19\n",
    "\n",
    "# show high res\n",
    "param['in'] = test_prefix + \"_d%03d\"%dataset + \"_%03d_ps.uni\"\n",
    "param['sdf'] = test_prefix + \"_d%03d\"%dataset + \"_%03d_sdf.uni\"\n",
    "param['t'] = data_param.frame_count\n",
    "param['res'] = low_res\n",
    "\n",
    "#param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_real_%03d_sdf_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show high-res data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py res 150 sdf 2D_data/highres/ref_sph_2D_v02_d019_%03d_sdf.uni in 2D_data/highres/ref_sph_2D_v02_d019_%03d_ps.uni t 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 19\n",
    "\n",
    "# show high res\n",
    "param['in'] = ref_prefix + \"_d%03d\"%dataset + \"_%03d_ps.uni\"\n",
    "param['sdf'] = ref_prefix + \"_d%03d\"%dataset + \"_%03d_sdf.uni\"\n",
    "param['t'] = data_param.frame_count\n",
    "param['res'] = data_param.res\n",
    "\n",
    "#param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_%03d_sdf_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show patches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_patches.py vel 2D_data/patches/lowres/sph_2D_v01-01_d000_010_vel src 2D_data/patches/lowres/sph_2D_v01-01_d000_010_sdf ref 2D_data/patches/highres/ref_sph_2D_v01-01_d000_010_sdf psize 5 ps 2D_data/patches/lowres/sph_2D_v01-01_d000_010_ps hpsize 15 t 1\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"2D_SPH/scenes/show_patches.py\", line 141, in <module>\n",
      "\n",
      "    s.step()\n",
      "\n",
      "RuntimeError: User interrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "timestep = 10\n",
    "var = 0\n",
    "\n",
    "# show patches\n",
    "param['src'] = src_patches_path + \"_d%03d_var%02d\"%(dataset,var) + \"_%03d_sdf\"%timestep\n",
    "param['vel'] = src_patches_path + \"_d%03d_var%02d\"%(dataset,var) + \"_%03d_vel\"%timestep\n",
    "param['ps'] =  src_patches_path + \"_d%03d_var%02d\"%(dataset,var) + \"_%03d_ps\" %timestep\n",
    "param['ref'] = ref_patches_path + \"_d%03d_var%02d\"%(dataset,var) + \"_%03d_sdf\"%timestep\n",
    "param['psize'] = pre_param.patch_size\n",
    "param['hpsize'] = high_patch_size\n",
    "param['t'] = 1#data_param.frame_count\n",
    "\n",
    "#param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_patch_%03d_sdf_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_patches.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_count: 4\n",
      "models/2D_data/sph_2D_v08\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Input, ZeroPadding2D, Dense\n",
    "from keras.layers import Reshape, RepeatVector, Permute, concatenate, add, Activation, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from subpixel import *\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "feature_cnt = 4\n",
    "print(\"feature_count: %d\" % feature_cnt)\n",
    "\n",
    "model = None\n",
    "\n",
    "model_path = 'models/%s%s_v%02d' % (data_loc, data_param.prefix, version)\n",
    "print(model_path)\n",
    "fig_path = '%s_loss' % model_path\n",
    "\n",
    "inputs = Input((pre_param.patch_size, pre_param.patch_size, 1), name=\"main_input\")\n",
    "auxiliary_input = Input(shape=(pre_param.patch_size, pre_param.patch_size, feature_cnt-1), name=\"auxiliary_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESPCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not nn_param.residual:\n",
    "    x = concatenate([inputs, auxiliary_input], name=\"concatenate\")\n",
    "    \n",
    "    x = Conv2D(filters=3, kernel_size=3, \n",
    "               strides=1, input_shape=input_shape, \n",
    "               activation='tanh', padding='same', name=\"conv2D_0\")(x)\n",
    "\n",
    "    x = Conv2D(filters=9, kernel_size=3,\n",
    "               strides=1, activation='tanh', padding='same', name=\"conv2D_1\")(x)\n",
    "\n",
    "    #model.add( keras.layers.BatchNormalization() )  \n",
    "\n",
    "    if nn_param.use_spc:\n",
    "        print(\"Use Subpixel Convolution\")\n",
    "        predictions = Subpixel(filters=1, kernel_size=3, r=3,activation='tanh', padding='same', name=\"subpixel_conv\")(x)\n",
    "    else:\n",
    "        x = Conv2DTranspose(filters=3, kernel_size=3, \n",
    "                            strides=int(factor_2D), activation='tanh', padding='same', name=\"deconv2D_0\")(x)\n",
    "        predictions = Conv2DTranspose(filters=1, kernel_size=3, \n",
    "                            strides=1, activation='tanh', padding='same', name=\"deconv2D_1\")(x)\n",
    "        \n",
    "    model = Model(inputs=[inputs,auxiliary_input], outputs=predictions)\n",
    "    model.summary()\n",
    "    model.compile( loss='mse', optimizer=keras.optimizers.adam(lr=nn_param.learning_rate))\n",
    "    \n",
    "    model.save(model_path + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual ESPCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 5, 5, 1)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "auxiliary_input (InputLayer)     (None, 5, 5, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate (Concatenate)        (None, 5, 5, 4)       0           main_input[0][0]                 \n",
      "                                                                   auxiliary_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_flat_res (Reshape)       (None, 100)           0           concatenate[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "repeate_res (RepeatVector)       (None, 9, 100)        0           reshape_flat_res[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "permute_res (Permute)            (None, 100, 9)        0           repeate_res[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_back_res (Reshape)       (None, 5, 5, 36)      0           permute_res[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2D_0 (Conv2D)                (None, 5, 5, 64)      20800       reshape_back_res[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "normalize_0 (BatchNormalization) (None, 5, 5, 64)      256         conv2D_0[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2D_1 (Conv2D)                (None, 5, 5, 128)     73856       normalize_0[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "normalize_1 (BatchNormalization) (None, 5, 5, 128)     512         conv2D_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_flat (Reshape)           (None, 25)            0           main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "deconv2D_0 (Conv2DTranspose)     (None, 5, 5, 64)      73792       normalize_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "repeate (RepeatVector)           (None, 9, 25)         0           reshape_flat[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "normalize_2 (BatchNormalization) (None, 5, 5, 64)      256         deconv2D_0[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "permute (Permute)                (None, 25, 9)         0           repeate[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "deconv2D_1 (Conv2DTranspose)     (None, 5, 5, 9)       5193        normalize_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_back (Reshape)           (None, 5, 5, 9)       0           permute[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "normalize_3 (BatchNormalization) (None, 5, 5, 9)       36          deconv2D_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add (Add)                        (None, 5, 5, 9)       0           reshape_back[0][0]               \n",
      "                                                                   normalize_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation (Activation)          (None, 5, 5, 9)       0           add[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "subpixel_conv (Subpixel)         (None, 15, 15, 1)     738         activation[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 175,439\n",
      "Trainable params: 174,909\n",
      "Non-trainable params: 530\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if nn_param.residual:   \n",
    "    base = Reshape((pre_param.patch_size*pre_param.patch_size,), name=\"reshape_flat\")(inputs)\n",
    "    base = RepeatVector(9, name=\"repeate\")(base)\n",
    "    base = Permute((2, 1), name=\"permute\")(base)\n",
    "    base = Reshape((pre_param.patch_size, pre_param.patch_size,9), name=\"reshape_back\")(base)\n",
    "    \n",
    "    x = concatenate([inputs, auxiliary_input], name=\"concatenate\")\n",
    "    x = Reshape((pre_param.patch_size*pre_param.patch_size*feature_cnt,), name=\"reshape_flat_res\")(x)\n",
    "    x = RepeatVector(9, name=\"repeate_res\")(x)\n",
    "    x = Permute((2, 1), name=\"permute_res\")(x)\n",
    "    x = Reshape((pre_param.patch_size, pre_param.patch_size,9*feature_cnt), name=\"reshape_back_res\")(x)\n",
    "    \n",
    "    #x = concatenate([base, auxiliary_input], name=\"concatenate\")\n",
    "    \n",
    "    x = Conv2D(filters=16*feature_cnt, kernel_size=3, \n",
    "               strides=1, activation='tanh', padding='same', name=\"conv2D_0\")(x)\n",
    "    x = BatchNormalization(name=\"normalize_0\")(x)\n",
    "    x = Conv2D(filters=32*feature_cnt, kernel_size=3,\n",
    "               strides=1, activation='tanh', padding='same', name=\"conv2D_1\")(x)    \n",
    "    x = BatchNormalization(name=\"normalize_1\")(x)\n",
    "    x = Conv2DTranspose(filters=16*feature_cnt, kernel_size=3, \n",
    "                        strides=1, activation='tanh', padding='same', name=\"deconv2D_0\")(x)\n",
    "    x = BatchNormalization(name=\"normalize_2\")(x)\n",
    "    x = Conv2DTranspose(filters=9, kernel_size=3, \n",
    "                        strides=1, activation='tanh', padding='same', name=\"deconv2D_1\")(x)\n",
    "    x = BatchNormalization(name=\"normalize_3\")(x)\n",
    "    \n",
    "    x = add([base,x], name=\"add\")\n",
    "    x = Activation('tanh', name=\"activation\")(x)\n",
    "    predictions = Subpixel(filters=1, kernel_size=3, r=3,activation='tanh', padding='same', name=\"subpixel_conv\")(x)\n",
    "    \n",
    "    generator = Model(inputs=[inputs,auxiliary_input], outputs=predictions, name=\"generator\")\n",
    "    generator.compile( loss='mse', optimizer=keras.optimizers.adam(lr=nn_param.learning_rate))\n",
    "    \n",
    "    generator.save(model_path + '.h5')\n",
    "    \n",
    "    generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 32)          320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 94,593\n",
      "Trainable params: 94,209\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if nn_param.adv_fac > 0.:\n",
    "    discriminator = Sequential(name=\"discriminator\")\n",
    "\n",
    "    img_shape = (high_patch_size, high_patch_size, 1)\n",
    "\n",
    "    discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    #model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    #model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #img = Input(shape=img_shape, name=\"disc_input\")\n",
    "    #validity = model(img)\n",
    "\n",
    "    #discriminator = Model(img, validity)\n",
    "\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.adam(lr=nn_param.learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    discriminator.save(model_path + '_dis.h5')\n",
    "\n",
    "    discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Script generated: train_sph_2D_v08.sh\n",
      "Execute Script for training: train_sph_2D_v08.sh\n"
     ]
    }
   ],
   "source": [
    "script = ShellScript(script_paths[\"train\"], \"python3 \" + manta_loc + (\"scenes/tools/train_gan.py\" if nn_param.adv_fac > 0. else \"scenes/tools/train_sequential.py\"))\n",
    "\n",
    "param = {}\n",
    "\n",
    "param['src'] = \"%spatches/%s/%s_v%02d-%02d\" % (data_loc, src, data_param.prefix, version_combi.data, version_combi.pre) + \"_d%03d_var%02d\" + \"_%03d\"\n",
    "param['ref'] = \"%spatches/%s/ref_%s_v%02d-%02d\" % (data_loc, ref, data_param.prefix, version_combi.data, version_combi.pre) + \"_d%03d_var%02d\" + \"_%03d\"\n",
    "param['data_start'] = 0\n",
    "param['data_end'] = nn_param.train_data_count\n",
    "param['time_start'] = nn_param.t_start\n",
    "param['time_end'] = nn_param.t_end\n",
    "param['var'] = pre_param.var\n",
    "param['features'] = \",\".join(nn_param.features)\n",
    "\n",
    "param['val_split'] = nn_param.val_split\n",
    "param['epochs'] = nn_param.epochs\n",
    "param['batch'] = nn_param.batch_size\n",
    "param['log_intervall'] = 10\n",
    "param['checkpoint_intervall'] = 10\n",
    "param['model'] = model_path\n",
    "param['fig'] = fig_path\n",
    "\n",
    "if nn_param.adv_fac > 0.:\n",
    "    param['lr'] = nn_param.learning_rate\n",
    "    param['mse'] = nn_param.mse_fac\n",
    "    param['adv'] = nn_param.adv_fac\n",
    "\n",
    "script.add_param(param)\n",
    "        \n",
    "script.write()\n",
    "print(\"Execute Script for training: \" + script_paths[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/2D_data/sph_2D_v08_loss.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-78184c10ecae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/2D_data/sph_2D_v08_loss.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=fig_path+\".png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from subpixel import *\n",
    "\n",
    "model = load_model('%smodel/%s_v%02d.h5' % (data_loc, data_param.prefix, version), custom_objects={'Subpixel': Subpixel})\n",
    "\n",
    "from dataset import Dataset\n",
    "src_patches_path = \"%spatches/%s/%s_v%02d-%02d\" % (data_loc, src, data_param.prefix, version_combi.data, version_combi.pre) + \"_d%03d_var%02d\" + \"_%03d\"\n",
    "print(src_patches_path)\n",
    "ref_patches_path = \"%spatches/%s/ref_%s_v%02d-%02d\" % (data_loc, ref, data_param.prefix, version_combi.data, version_combi.pre) + \"_d%03d_var%02d\" + \"_%03d\"\n",
    "print(ref_patches_path)\n",
    "\n",
    "test_data = Dataset(src_patches_path, \n",
    "                    nn_param.train_data_count, nn_param.train_data_count + nn_param.test_data_count, nn_param.t_start, nn_param.t_end, \n",
    "                    nn_param.features, pre_param.var, ref_patches_path, ['sdf'])\n",
    "\n",
    "print(train_data.data.shape)\n",
    "print(train_data.ref_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816/2860 [============================>.] - ETA: 0s0.120119651459\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x=np.split(test_data.data,[1],axis=3), y=test_data.ref_data, batch_size=nn_param.batch_size)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from uniio import *\n",
    "\n",
    "timestep = (nn_param.t_start + nn_param.t_end) // 2\n",
    "\n",
    "test_filename = \"%sresult/%s_v%02d\" % (data_loc, data_param.prefix, version) + \"_%03d_sdf\" % timestep\n",
    "ref_filename = \"%sresult/ref_%s_v%02d\" % (data_loc, data_param.prefix, version) + \"_%03d_sdf\" % timestep\n",
    "result_filename = \"%sresult/result_%s_v%02d\" % (data_loc, data_param.prefix, version) + \"_%03d_sdf\" % timestep\n",
    "\n",
    "#remove_data(test_filename)\n",
    "#remove_data(ref_filename)\n",
    "#remove_data(result_filename)\n",
    "\n",
    "result = model.predict(x=np.split(test_data.data,[1],axis=3), batch_size=nn_param.batch_size)\n",
    "\n",
    "for patch in test_data.data:\n",
    "    writeNumpyBuf(test_filename, patch[:,:,0])\n",
    "    \n",
    "for patch in test_data.ref_data:\n",
    "    writeNumpyBuf(ref_filename, patch)\n",
    "    \n",
    "for patch in result:\n",
    "    writeNumpyBuf(result_filename, patch)\n",
    "    \n",
    "finalizeNumpyBufs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_patches.py ref 2D_data/result/result_sph_2D_v05_010_sdf ref2 2D_data/result/ref_sph_2D_v05_010_sdf scr 2D_data/screenshots/20171121/sph_patch_%03d_sdf_res.png src 2D_data/result/sph_2D_v05_010_sdf t 1 psize 5 hpsize 15\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"2D_SPH/scenes/show_patches.py\", line 141, in <module>\n",
      "\n",
      "    s.step()\n",
      "\n",
      "RuntimeError: User interrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "\n",
    "# show patches\n",
    "param['src'] = test_filename\n",
    "param['ref'] = result_filename\n",
    "param['ref2'] = ref_filename\n",
    "param['psize'] = pre_param.patch_size\n",
    "param['hpsize'] = high_patch_size\n",
    "param['t'] = 1\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_patch_%03d_sdf_res.png\"\n",
    "\n",
    "run_manta(\"scenes/show_patches.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 152, 1)\n",
      "2D_data/test/sph_2D_v02_d018_%03d\n",
      "2D_data/highres/ref_sph_2D_v02_d018_%03d_sdf.uni\n",
      "2D_data/result/sph_2D_v05_d018_%03d_result.uni\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage.filters as fi\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "use_real_data = True\n",
    "\n",
    "def filter2D(kernlen, s, fac):\n",
    "    dirac = np.zeros((kernlen, kernlen))\n",
    "    dirac[kernlen//2, kernlen//2] = 1\n",
    "    return np.clip(fi.gaussian_filter(dirac, s) * fac, a_min=None, a_max=1.0)\n",
    "\n",
    "result = np.ndarray(shape=(data_param.res,data_param.res,1), dtype=float)\n",
    "#weights = np.ndarray(shape=(data_param.res,data_param.res,1), dtype=float)\n",
    "#weights.fill(0)\n",
    "\n",
    "ps = pre_param.patch_size//2\n",
    "hps = high_patch_size//2\n",
    "\n",
    "border = int(math.ceil(hps-(ps*factor_2D)))\n",
    "\n",
    "result=np.pad(result,((border,border),(border,border),(0,0)),mode=\"edge\")\n",
    "#weights=np.pad(weights,((border,border),(border,border),(0,0)),mode=\"edge\")\n",
    "print(result.shape)\n",
    "dataset = 18#nn_param.train_data_count\n",
    "var = 0\n",
    "\n",
    "input_path = (test_prefix if use_real_data else src_prefix) + \"_d%03d\" % dataset + (\"_var%02d\"%var if not use_real_data else \"\") + \"_%03d\"\n",
    "ref_input_path = ref_prefix + \"_d%03d\" % dataset + \"_%03d_sdf.uni\"\n",
    "print(input_path)\n",
    "print(ref_input_path)\n",
    "output_path = \"%sresult/%s_v%02d_d%03d\" % (data_loc, data_param.prefix, version, dataset) + \"_%03d_result.uni\"\n",
    "print(output_path)\n",
    "\n",
    "elem_min = np.vectorize(lambda x,y: min(x,y))\n",
    "circular_filter = filter2D(high_patch_size, high_patch_size*0.2, 500)\n",
    "\n",
    "for t in range(nn_param.t_start, nn_param.t_end):\n",
    "    result.fill(1)\n",
    "    hdr, source = readUni(input_path%t+\"_sdf.uni\")\n",
    "    for f in nn_param.features:\n",
    "        if f != \"sdf\":\n",
    "            _, tmp = readUni(input_path%t+\"_\"+f+\".uni\")\n",
    "            source = np.append(source, tmp, axis=3)\n",
    "\n",
    "    for x in range (ps, low_res-ps, 1):\n",
    "        for y in range(ps, low_res-ps, 1):\n",
    "            if(abs(source[0,x,y,0]) < pre_param.surf):\n",
    "                x0=x-ps\n",
    "                x1=x+ps+1\n",
    "                y0=y-ps\n",
    "                y1=y+ps+1\n",
    "                \n",
    "                data = np.array([source[0,x0:x1,y0:y1]]) * pre_param.l_fac\n",
    "                if pre_param.use_tanh != 0:\n",
    "                    data[0,:,:,0] = np.tanh(data[0,:,:,0])\n",
    "                \n",
    "                predict = model.predict(x=np.split(data,[1],axis=3), batch_size=1)\n",
    "                if pre_param.use_tanh != 0:\n",
    "                    predict = np.arctanh(np.clip(predict,-.999999,.999999))\n",
    "                    \n",
    "                predict = predict * circular_filter/pre_param.h_fac\n",
    "\n",
    "                x0=int(factor_2D*x)-hps+border\n",
    "                x1=int(factor_2D*x)+hps+border+1\n",
    "                y0=int(factor_2D*y)-hps+border\n",
    "                y1=int(factor_2D*y)+hps+border+1\n",
    "\n",
    "                result[x0:x1,y0:y1,0] = elem_min(result[x0:x1,y0:y1,0], predict[0,:,:,0])\n",
    "\n",
    "    hdr['dimX'] = data_param.res\n",
    "    hdr['dimY'] = data_param.res\n",
    "\n",
    "    #print(result[border:data_param.res+border,border:data_param.res+border,0].shape)\n",
    "    writeUni(output_path%t, hdr, result[border:data_param.res+border,border:data_param.res+border,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Init show frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scr_path =  (\"real_\" if use_real_data else \"\") + \"%s_v%02d_d%03d\" % (data_param.prefix, version, dataset) + \"_%03d\"\n",
    "if nn_param.t_end - nn_param.t_start <= 1: \n",
    "    scr_path = scr_path % nn_param.t_start\n",
    "    input_path = input_path % nn_param.t_start\n",
    "    output_path = output_path % nn_param.t_start\n",
    "    ref_input_path = ref_input_path % nn_param.t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naiive Up-res**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/up_scale.py t_end 15 upres 150 scr 2D_data/screenshots/20171121/simple_sph_2D_v05_d018_%03d.png res 50 sdf 2D_data/lowres/sph_2D_v02-02_d018_var00_%03d_sdf.uni t_start 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "# show input\n",
    "param['sdf'] = input_path+\"_sdf.uni\"\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = low_res\n",
    "param['upres'] = data_param.res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + 'simple_' + scr_path + \".png\"\n",
    "\n",
    "run_manta(\"scenes/up_scale.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show source frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py res 50 sres 2 t_start 5 sdf 2D_data/lowres/sph_2D_v02-02_d018_var00_%03d_sdf.uni scr 2D_data/screenshots/20171123/src_sph_2D_v05_d018_%03d.png t_end 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "# show input\n",
    "param['sdf'] = input_path+\"_sdf.uni\"\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = low_res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + 'src_' + scr_path + \".png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show result frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py res 150 sres 2 t_start 5 sdf 2D_data/result/sph_2D_v05_d018_%03d_result.uni scr 2D_data/screenshots/20171123/res_real_sph_2D_v05_d018_%03d.png t_end 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "# show result\n",
    "param['sdf'] = output_path\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + 'res_' + scr_path + \".png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show reference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py sres 2 t_end 15 scr 2D_data/screenshots/20171121/ref_sph_2D_v05_d018_%03d.png res 150 sdf 2D_data/highres/ref_sph_2D_v02_d018_%03d_sdf.uni t_start 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "# show result\n",
    "param['sdf'] = ref_input_path\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + 'ref_' + scr_path + \".png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_data/patches/lowres/sph_2D_v01-01_d%03d_%03d\n",
      "2D_data/patches/highres/ref_sph_2D_v01-01_d%03d_%03d\n",
      "(6510, 100)\n",
      "(6510, 1000)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"2D_SPH/scenes/tools\")\n",
    "from uniio import *\n",
    "from dataset import Dataset\n",
    "\n",
    "src_patches_path = \"2D_data/patches/lowres/sph_2D_v01-01_d%03d_%03d\"\n",
    "print(src_patches_path)\n",
    "ref_patches_path = \"2D_data/patches/highres/ref_sph_2D_v01-01_d%03d_%03d\"\n",
    "print(ref_patches_path)\n",
    "\n",
    "train_data = Dataset(src_patches_path, \n",
    "                     0, 9, 5, 15, \n",
    "                     ['ps'], ref_patches_path, ['ps'])\n",
    "#test_data = Dataset(src_patches_path, ref_patches_path, \n",
    "#                    nn_param.train_data_count, nn_param.train_data_count + nn_param.test_data_count, nn_param.t_start, nn_param.t_end, \n",
    "#                    nn_param.features, ['sdf'])\n",
    "\n",
    "print(train_data.data.shape)\n",
    "print(train_data.ref_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(100,), activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 - loss: 19992.541534 val_loss: 56.722551\n",
      "10/100 - loss: 55.696776 val_loss: 56.144690\n",
      "20/100 - loss: 55.068462 val_loss: 55.594103\n",
      "30/100 - loss: 54.522375 val_loss: 55.072018\n",
      "40/100 - loss: 54.274731 val_loss: 54.760774\n",
      "50/100 - loss: 54.215486 val_loss: 54.677540\n",
      "60/100 - loss: 54.183672 val_loss: 54.673735\n",
      "70/100 - loss: 54.220620 val_loss: 54.757098\n",
      "80/100 - loss: 54.212504 val_loss: 54.949502\n",
      "90/100 - loss: 54.199258 val_loss: 54.657104\n",
      "100/100 - loss: 54.170859 val_loss: 54.750958\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGHCAYAAABSw0P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126f93ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NthLogger(keras.callbacks.Callback):\n",
    "    def __init__(self,n=10):\n",
    "        self.act = 0\n",
    "        self.n = n\n",
    "\n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.act += 1\n",
    "        if self.act % self.n == 0 or self.act == 1:\n",
    "            print('%d/%d - loss: %f val_loss: %f' % (self.act, self.params['epochs'], logs['loss'], logs['val_loss']))\n",
    "\n",
    "history = model.fit(x=train_data.data,y=train_data.ref_data, validation_split=0.2, \n",
    "                    epochs=100, batch_size=32, \n",
    "                    verbose=0, callbacks=[NthLogger()])\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_005_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_006_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_007_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_008_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_009_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_010_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_011_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_012_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_013_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n",
      "Reading 2D_data/lowres/sph_2D_v01-01_d004_014_ps.uni ... \n",
      "(BasicParticleSystem) \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage.filters as fi\n",
    "import math\n",
    "\n",
    "ps = 5//2\n",
    "hps = 15//2\n",
    "\n",
    "dataset = 4#nn_param.train_data_count\n",
    "\n",
    "input_path = src_prefix + \"_d%03d\" % dataset + \"_%03d\"\n",
    "ref_input_path = ref_prefix + \"_d%03d\" % dataset + \"_%03d_sdf.uni\"\n",
    "output_path = \"%sresult/%s_v%02d_d%03d\" % (data_loc, data_param.prefix, version, dataset) + \"_%03d_ps_result.uni\"\n",
    "\n",
    "def particle_range(arr, start, end):\n",
    "    for i in range(len(start)):\n",
    "        arr = arr[np.where((arr[:,i]>=start[i])&(arr[:,i]<=end[i]))]\n",
    "    return arr\n",
    "\n",
    "for t in range(5, 15):\n",
    "    result = None\n",
    "    hdr, particle_src = readParticles(input_path%t+\"_ps.uni\")\n",
    "    sdf_source = readUni(input_path%t+\"_sdf.uni\")[1]\n",
    "\n",
    "    for x in range (ps, low_res-ps, 1):\n",
    "        for y in range(ps, low_res-ps, 1):\n",
    "            if(abs(sdf_source[0,x,y,0]) < 0.5):\n",
    "                x0=x-ps\n",
    "                x1=x+ps+1\n",
    "                y0=y-ps\n",
    "                y1=y+ps+1\n",
    "                \n",
    "                v = np.subtract(particle_range(particle_src, [y0,x0],[y1,x1]),[y0,x0,0])\n",
    "                v = v[:,0]\n",
    "                np.random.shuffle(v)\n",
    "                v = np.resize(v,100)\n",
    "                #np.random.shuffle(v)\n",
    "                \n",
    "                predict = model.predict(x=np.array([v]), batch_size=1)\n",
    "                \n",
    "                predict = np.reshape(predict, (500,2))\n",
    "                predict = np.concatenate((predict, np.full((500,1),0.5)), axis=1)\n",
    "                \n",
    "                if result is None:\n",
    "                    result = np.add(predict,[y0,x0,0])\n",
    "                else:\n",
    "                    result = np.concatenate((result, np.add(predict,[y0,x0,0])), axis=0)\n",
    "\n",
    "    hdr['dim'] = len(result)\n",
    "\n",
    "    #print(result[border:data_param.res+border,border:data_param.res+border,0].shape)\n",
    "    writeParticles(output_path%t, hdr, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py in 2D_data/result/sph_2D_v03_d004_%03d_ps_result.uni res 150 sdf 2D_data/highres/ref_sph_2D_v01_d004_%03d_sdf.uni t_end 15 t_start 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 4\n",
    "\n",
    "# show high res\n",
    "param['in'] = output_path\n",
    "param['sdf'] = ref_prefix + \"_d%03d\"%dataset + \"_%03d_sdf.uni\"\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = data_param.res\n",
    "\n",
    "#param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_%03d_sdf_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.]\n",
      "   [ 1.]\n",
      "   [ 2.]]\n",
      "\n",
      "  [[ 3.]\n",
      "   [ 4.]\n",
      "   [ 5.]]\n",
      "\n",
      "  [[ 6.]\n",
      "   [ 7.]\n",
      "   [ 8.]]]]\n",
      "+\n",
      "[[[[ 10.]\n",
      "   [ 11.]\n",
      "   [ 12.]]\n",
      "\n",
      "  [[ 13.]\n",
      "   [ 14.]\n",
      "   [ 15.]]\n",
      "\n",
      "  [[ 16.]\n",
      "   [ 17.]\n",
      "   [ 18.]]]]\n",
      "=>\n",
      "[[[[  0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  10.  10.  10.  10.\n",
      "     10.  10.  10.  10.]\n",
      "   [  1.   1.   1.   1.   1.   1.   1.   1.   1.  11.  11.  11.  11.  11.\n",
      "     11.  11.  11.  11.]\n",
      "   [  2.   2.   2.   2.   2.   2.   2.   2.   2.  12.  12.  12.  12.  12.\n",
      "     12.  12.  12.  12.]]\n",
      "\n",
      "  [[  3.   3.   3.   3.   3.   3.   3.   3.   3.  13.  13.  13.  13.  13.\n",
      "     13.  13.  13.  13.]\n",
      "   [  4.   4.   4.   4.   4.   4.   4.   4.   4.  14.  14.  14.  14.  14.\n",
      "     14.  14.  14.  14.]\n",
      "   [  5.   5.   5.   5.   5.   5.   5.   5.   5.  15.  15.  15.  15.  15.\n",
      "     15.  15.  15.  15.]]\n",
      "\n",
      "  [[  6.   6.   6.   6.   6.   6.   6.   6.   6.  16.  16.  16.  16.  16.\n",
      "     16.  16.  16.  16.]\n",
      "   [  7.   7.   7.   7.   7.   7.   7.   7.   7.  17.  17.  17.  17.  17.\n",
      "     17.  17.  17.  17.]\n",
      "   [  8.   8.   8.   8.   8.   8.   8.   8.   8.  18.  18.  18.  18.  18.\n",
      "     18.  18.  18.  18.]]]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "i = keras.layers.Input((3,3,1))\n",
    "ai = keras.layers.Input((3,3,1))\n",
    "x = concatenate([i, ai])\n",
    "x = Reshape((3*3*2,))(x)\n",
    "x = RepeatVector(9)(x)\n",
    "x = Permute((2, 1))(x)\n",
    "x = Reshape((3, 3, 18))(x)\n",
    "    \n",
    "#x = concatenate([x, ai])\n",
    "\n",
    "#x = i\n",
    "\n",
    "#x = Conv2D(filters=1, kernel_size=3, strides=1, padding='same', name=\"conv\")(x)\n",
    "\n",
    "model = keras.layers.Model(inputs=[i,ai],outputs=x)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.adam(lr=0.1))\n",
    "\n",
    "data = np.array([[[[0.],[1.],[2.]],[[3.],[4.],[5.]],[[6.],[7.],[8.]]]])\n",
    "aux = np.array([[[[10.],[11.],[12.]],[[13.],[14.],[15.]],[[16.],[17.],[18.]]]])\n",
    "print(data)\n",
    "print(\"+\")\n",
    "print(aux)\n",
    "print(\"=>\")\n",
    "print(model.predict([data,aux]))\n",
    "#print(model.get_layer(\"conv\").get_weights()[0].shape)\n",
    "#print(model.get_layer(\"conv\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
