{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Particles 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Dataset\n",
    "Pipeline:\n",
    "* Generation of high-res data (reference) using some random cubes of water\n",
    "* Extracting relevant data (particle data and grid data) like e.g. sdf, velocity, pressure, density...\n",
    "* Down-sampling of particles (by a given factor) and generation of the low-res data (source)\n",
    "* Extract corresponding and relevant patches on the surface from the data-set pairs (considering the low-res data)\n",
    "* Use patche-pairs to train the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple structs containing parameters for different data-set and neural network versions.\n",
    "\n",
    "Data-set Parameters:\n",
    "* **prefix**: prefix of filename\n",
    "* **nn_version**: used neural network version\n",
    "* **patch_size**: size of generated surface patches (of the low-res data)\n",
    "* **stride**: stride used for the generation of the patches\n",
    "* **surf**: surface tolerance, specifies which sdf-values are considered as surface (for patches)\n",
    "* **fps**: frames per second, the velocity of the simulation\n",
    "* **frame_count**: count of generated frames\n",
    "* **sub_res**: count of particles per cell (per dimension)\n",
    "* **res**: resolution of high-res grid\n",
    "* **var1**: factor of drop falling in basin data-sets (var0 is 1 - var1 - var2)\n",
    "* **var2**: factor of two drop shooting against other\n",
    "* **factor**: goal up-scale factor of particles\n",
    "* **upres**: specify if the low-res grids will be up-scaled to res (=> input and output same scale)\n",
    "* **l_fac**: multiplicative factor of low-res sdf-patches\n",
    "* **h_fac**: multiplicative factor of high-res sdf-patches\n",
    "* **use_tanh**: apply tanh on sdf-patches, after multiplication with factor\n",
    "* **seed**: seed for random data-set generation\n",
    "* **min_scale**: minimum scale of boxes for data-set generation\n",
    "* **max_scale**: maximum scale of boxes for data-set generation\n",
    "* **min_pos**: minimum x-position of boxes\n",
    "* **max_pos**: maximum x-position of boxes\n",
    "* **max_h**: maximum start-height of boxes\n",
    "* **max_cnt**: maximum count of boxes\n",
    "* **circ_vel**: velocity used for colliding drops\n",
    "\n",
    "Neural Network Parameters:\n",
    "* **train_data_count**: count of training data-sets\n",
    "* **val_split**: factor of how much of training data is used for validation\n",
    "* **test_data_count**: count of test data-sets\n",
    "* **t_start**: timestep start-point of data\n",
    "* **t_end**: timestep end-point of data\n",
    "* **features**: list of strings which specifiy which features to use:\n",
    "    * 'sdf': levelset data\n",
    "    * 'vel': velocity data\n",
    "    * 'dens': density data\n",
    "    * 'pres': pressure data\n",
    "* **batch_size**: batch size used for training and validation\n",
    "* **learning_rate**: learing rate used for training\n",
    "* **epochs**: training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DatasetParam:\n",
    "    def __init__(self, prefix=\"sph_2D\", nn_version=0, patch_size=9, stride=3, surf=0.2, \n",
    "                fps=30, frame_count=50, sub_res=2, res=150, factor=10, upres=1, var1=0, var2=0,\n",
    "                l_fac=1.0,h_fac=1.0,use_tanh=0,\n",
    "                seed=124820112, min_scale=0.05, max_scale=0.3,\n",
    "                min_pos=0.2,max_pos=0.8,max_h=0.1,max_cnt=5, circ_vel=100.):\n",
    "    \n",
    "        self.prefix = prefix\n",
    "        self.nn_version = nn_version\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.surf = surf\n",
    "        \n",
    "        self.l_fac = l_fac\n",
    "        self.h_fac = h_fac\n",
    "        self.use_tanh = use_tanh\n",
    "\n",
    "        self.fps = fps\n",
    "        self.frame_count = frame_count\n",
    "        self.sub_res = sub_res\n",
    "        self.res = res\n",
    "        self.factor = factor\n",
    "        self.upres = upres\n",
    "        \n",
    "        self.var1 = var1\n",
    "        self.var2 = var2\n",
    "\n",
    "        self.seed = seed\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.min_pos = min_pos\n",
    "        self.max_pos = max_pos\n",
    "        self.max_h = max_h\n",
    "        self.max_cnt = max_cnt    \n",
    "        self.circ_vel = circ_vel\n",
    "\n",
    "class NNParam:\n",
    "    def __init__(self, train_data_count=5, val_split=0.2, test_data_count=1,\n",
    "                 t_start = 20, t_end = 21, features=['sdf'], \n",
    "                 batch_size=32,learning_rate=0.002,epochs=1000, use_spc=False):\n",
    "        self.train_data_count = train_data_count\n",
    "        self.val_split = val_split\n",
    "        self.test_data_count = test_data_count\n",
    "        self.t_start = t_start\n",
    "        self.t_end = t_end\n",
    "        self.features = features\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.use_spc = use_spc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Version:\n",
    "* **V0**: default values, input and output patches same size\n",
    "* **V1**: smaller patches, input and output patches different size, uses simple post-processing of patches\n",
    "* **V2**: different seed, uses different data-set types\n",
    "\n",
    "NN Version:\n",
    "* **V0**: CNN with only sdf data\n",
    "* **V1**: also velocity as input\n",
    "* **V2**: 'Subpixel Convolution' instead of 'Transposed Convolution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_version_param = [\n",
    "    DatasetParam(),\n",
    "    DatasetParam(upres=0,\n",
    "                 factor=9,\n",
    "                 stride=2,\n",
    "                 surf=0.5,\n",
    "                 patch_size=5,\n",
    "                 nn_version=1,\n",
    "                 l_fac=3.0,\n",
    "                 use_tanh=1),\n",
    "    DatasetParam(upres=0,\n",
    "                 factor=9,\n",
    "                 stride=2,\n",
    "                 surf=0.5,\n",
    "                 patch_size=5,\n",
    "                 nn_version=2,\n",
    "                 h_fac=4.,\n",
    "                 l_fac=12.,\n",
    "                 seed=123412144,\n",
    "                 use_tanh=1,\n",
    "                 var1=3./9,\n",
    "                 var2=3./9)\n",
    "]\n",
    "\n",
    "nn_version_param = [\n",
    "    NNParam(),\n",
    "    NNParam(train_data_count=9, \n",
    "            test_data_count=1, \n",
    "            t_start=5,\n",
    "            t_end=15,\n",
    "            epochs=200,\n",
    "            features=['sdf','vel']),\n",
    "    NNParam(train_data_count=9, \n",
    "            test_data_count=1, \n",
    "            t_start=5,\n",
    "            t_end=15,\n",
    "            epochs=200,\n",
    "            features=['sdf','vel'],\n",
    "            use_spc=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"2D_SPH/scenes/tools\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "manta_loc = \"2D_SPH/\"\n",
    "\n",
    "data_version = 2\n",
    "data_param = data_version_param[data_version]\n",
    "\n",
    "nn_param = nn_version_param[data_param.nn_version]\n",
    "\n",
    "data_loc = \"2D_data/\"\n",
    "src = \"lowres\"\n",
    "ref = \"highres\"\n",
    "\n",
    "# count of training/validation setups\n",
    "data_count = nn_param.train_data_count + nn_param.test_data_count\n",
    "\n",
    "verbose = False\n",
    "\n",
    "def createFolder(p):\n",
    "    if not os.path.exists(p):\n",
    "        os.makedirs(p)\n",
    "    \n",
    "def create_curr_date_folder(path):\n",
    "    now = datetime.datetime.now()\n",
    "    path += \"%04d%02d%02d\"%(now.year,now.month,now.day)\n",
    "    createFolder(path)\n",
    "    return path + \"/\"\n",
    "\n",
    "createFolder(data_loc)\n",
    "createFolder(data_loc+src)\n",
    "createFolder(data_loc+ref)\n",
    "createFolder(data_loc+\"patches\")\n",
    "createFolder(data_loc+\"patches/\"+src)\n",
    "createFolder(data_loc+\"patches/\"+ref)\n",
    "createFolder(data_loc+\"result\")\n",
    "createFolder(data_loc+\"screenshots\")\n",
    "\n",
    "src_prefix = \"%s%s/%s_v%02d\" % (data_loc, src, data_param.prefix, data_version)\n",
    "ref_prefix = \"%s%s/ref_%s_v%02d\" % (data_loc, ref, data_param.prefix, data_version)\n",
    "\n",
    "def remove_data(path_prefix):\n",
    "    command = [\"rm\", path_prefix+\"*\"]\n",
    "    print(\" \".join(command) + \"\\n\")\n",
    "    proc = Popen(command, stdin=None, stdout=PIPE, stderr=PIPE)\n",
    "    if verbose:\n",
    "        for line in proc.stdout:\n",
    "            print(line.decode('utf-8'))\n",
    "    for line in proc.stderr:\n",
    "        print(line.decode('utf-8'))\n",
    "\n",
    "def run_manta(scene, param={},run=True):\n",
    "    command = [manta_loc+\"build/manta\", manta_loc+scene]\n",
    "\n",
    "    for k, v in param.items():\n",
    "        command += [k, str(v)]\n",
    "        \n",
    "    print(\" \".join(command) + \"\\n\")\n",
    "    \n",
    "    if not run: return\n",
    "\n",
    "    proc = Popen(command, stdin=None, stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "    if verbose:\n",
    "        for line in proc.stdout:\n",
    "            print(line.decode('utf-8'))\n",
    "    for line in proc.stderr:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute 2D down-scale factor:\n",
    "$$lowres=\\frac{res}{\\sqrt(factor)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D factor: 3.000000\n",
      "low resolution: 50\n",
      "big patch size. 15\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#remove_data(src_prefix)\n",
    "\n",
    "low_res = data_param.res\n",
    "high_patch_size = data_param.patch_size\n",
    "factor_2D = 1.\n",
    "if not data_param.upres:\n",
    "    factor_2D = math.sqrt(data_param.factor)\n",
    "    low_res = int(low_res/factor_2D)\n",
    "    high_patch_size = int(high_patch_size*factor_2D)\n",
    "    \n",
    "print(\"2D factor: %f\" % factor_2D)\n",
    "print(\"low resolution: %d\" % low_res)\n",
    "print(\"big patch size. %d\" % high_patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate High-res Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRINTS ONLY CALLS! RUN NOT ACTIVATED\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py out 2D_data/highres/ref_sph_2D_v02_d000_%03d sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c_cnt 1 c0 0.494799,0.117561,0.235628,0.121357\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.408424,0.188316,0.289150,0.235498 out 2D_data/highres/ref_sph_2D_v02_d001_%03d c2 0.698192,0.163711,0.081849,0.172705 c3 0.387485,0.126930,0.208639,0.167533 sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c4 0.499663,0.072849,0.262631,0.087050 c_cnt 5 c0 0.646937,0.079092,0.167751,0.106881\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.313436,0.106486,0.201034,0.203649 out 2D_data/highres/ref_sph_2D_v02_d002_%03d c2 0.540229,0.145842,0.143475,0.201570 c3 0.402537,0.077487,0.243389,0.112155 sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c4 0.613239,0.133980,0.259161,0.238037 c_cnt 5 c0 0.549986,0.153319,0.245289,0.122646\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.675735,0.262788,0.083569,0.079521 out 2D_data/highres/ref_sph_2D_v02_d003_%03d c2 0.459522,0.257921,0.072870,0.092490 sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c_cnt 3 c0 0.000000,0.050000,1.000000,0.100000\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.732694,0.331416,0.098571,0.075397 out 2D_data/highres/ref_sph_2D_v02_d004_%03d c2 0.345070,0.338960,0.105172,0.054843 sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c_cnt 3 c0 0.000000,0.050000,1.000000,0.100000\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.712665,0.347199,0.143808,0.098468 out 2D_data/highres/ref_sph_2D_v02_d005_%03d c2 0.355382,0.350163,0.131639,0.049820 sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c_cnt 3 c0 0.000000,0.050000,1.000000,0.100000\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.487061,0.256150,0.099268,0.081688 out 2D_data/highres/ref_sph_2D_v02_d006_%03d c2 0.551380,0.342911,0.083467,0.109923 c3 0.603760,0.747565,0.047190,0.038494 sres 2 fps 30 gui 0 circ 100.0 res 150 t_end 1.6666666666666667 c_cnt 4 c0 0.541419,0.715370,0.106910,0.060513\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.536091,0.457829,0.123292,0.045113 out 2D_data/highres/ref_sph_2D_v02_d007_%03d c2 0.382102,0.291890,0.112261,0.107442 c3 0.421570,0.424714,0.115647,0.064992 sres 2 fps 30 gui 0 circ 100.0 res 150 t_end 1.6666666666666667 c4 0.684415,0.737635,0.086952,0.049490 c_cnt 5 c0 0.551953,0.573224,0.088086,0.062675\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.551649,0.274983,0.068132,0.039717 out 2D_data/highres/ref_sph_2D_v02_d008_%03d c2 0.519588,0.306197,0.041900,0.040151 c3 0.311003,0.266587,0.142896,0.113259 sres 2 fps 30 gui 0 circ 100.0 res 150 t_end 1.6666666666666667 c_cnt 4 c0 0.512693,0.614078,0.092329,0.085174\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/2D_sph.py c1 0.585933,0.122269,0.117856,0.156648 out 2D_data/highres/ref_sph_2D_v02_d009_%03d sres 2 fps 30 gui 0 circ 0 res 150 t_end 1.6666666666666667 c_cnt 2 c0 0.403119,0.083878,0.249273,0.057324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#remove_data(ref_prefix)\n",
    "\n",
    "run = False\n",
    "if not run: print(\"PRINTS ONLY CALLS! RUN NOT ACTIVATED\\n\")\n",
    "    \n",
    "param = {}\n",
    "\n",
    "#disable gui\n",
    "param['gui'] = 0\n",
    "\n",
    "# resolution of domain\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "# output file format\n",
    "param['out'] = ref_prefix\n",
    "\n",
    "# write only every 30th frame -> 30 frames are one timestep\n",
    "param['fps'] = data_param.fps\n",
    "\n",
    "# simulation time (how many frames)\n",
    "param['t_end'] = float(data_param.frame_count) / data_param.fps\n",
    "\n",
    "# run random training setups\n",
    "random.seed(data_param.seed)\n",
    "\n",
    "def call_dataset_gen(var0,var1,var2,off):\n",
    "    if run: print(\"var0: %d, var1: %d, var2: %d\" % (var0, var1, var2))\n",
    "\n",
    "    param['circ'] = 0\n",
    "    for i in range(var0):\n",
    "        param['out'] = (ref_prefix + \"_d%03d\")%off + \"_%03d\"\n",
    "\n",
    "        # generate different cubes with dataformat \"pos_x,pos_y,scale_x,scale_y\"\n",
    "        param['c_cnt'] = random.randint(1,data_param.max_cnt)\n",
    "        cubes = {}\n",
    "        for c in range(param['c_cnt']):    \n",
    "            scx = random.uniform(data_param.min_scale, data_param.max_scale)\n",
    "            scy = random.uniform(data_param.min_scale, data_param.max_scale)\n",
    "            px = random.uniform(data_param.min_pos+scx/2, data_param.max_pos-scx/2)\n",
    "            py = random.uniform(0, data_param.max_h) + scy/2\n",
    "            cubes['c%d'%c] = \"%f,%f,%f,%f\"%(px,py,scx,scy)\n",
    "        run_manta(\"scenes/2D_sph.py\", dict(param, **cubes), run)\n",
    "        off+=1\n",
    "\n",
    "    for i in range(var1):\n",
    "        param['out'] = (ref_prefix + \"_d%03d\")%off + \"_%03d\"\n",
    "\n",
    "        # generate different cubes with dataformat \"pos_x,pos_y,scale_x,scale_y\"\n",
    "        param['c_cnt'] = random.randint(2,data_param.max_cnt)\n",
    "        cubes = {}\n",
    "\n",
    "        scy = data_param.max_h\n",
    "        cubes['c0'] = \"%f,%f,%f,%f\"%(0, scy/2, 1, scy)\n",
    "        for c in range(1,param['c_cnt']):    \n",
    "            scx = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            scy = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            px = random.uniform(data_param.min_pos+scx/2, data_param.max_pos-scx/2)\n",
    "            py = random.uniform(data_param.min_pos+scy/2, data_param.max_pos*0.5-scy/2)\n",
    "            cubes['c%d'%c] = \"%f,%f,%f,%f\"%(px,py,scx,scy)\n",
    "        run_manta(\"scenes/2D_sph.py\", dict(param, **cubes), run)\n",
    "        off+=1\n",
    "\n",
    "    param['circ'] = data_param.circ_vel\n",
    "    for i in range(var2):\n",
    "        param['out'] = (ref_prefix + \"_d%03d\")%off + \"_%03d\"\n",
    "\n",
    "        # generate different cubes with dataformat \"pos_x,pos_y,scale_x,scale_y\"\n",
    "        param['c_cnt'] = random.randint(2,data_param.max_cnt)\n",
    "        cubes = {}\n",
    "        for c in range(param['c_cnt']):    \n",
    "            scx = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            scy = random.uniform(data_param.min_scale, data_param.max_scale)*0.5\n",
    "            px = random.uniform(data_param.min_pos+scx/2, data_param.max_pos-scx/2)\n",
    "            py = random.uniform(data_param.min_pos+scy/2, data_param.max_pos-scy/2)\n",
    "            cubes['c%d'%c] = \"%f,%f,%f,%f\"%(px,py,scx,scy)\n",
    "        run_manta(\"scenes/2D_sph.py\", dict(param, **cubes), run)\n",
    "        off+=1\n",
    "    \n",
    "var1 = int(nn_param.train_data_count * data_param.var1)\n",
    "var2 = int(nn_param.train_data_count * data_param.var2)\n",
    "var0 = nn_param.train_data_count - var1 - var2\n",
    "\n",
    "call_dataset_gen(var0,var1,var2,0)\n",
    "\n",
    "var1 = int(nn_param.test_data_count * data_param.var1)\n",
    "var2 = int(nn_param.test_data_count * data_param.var2)\n",
    "var0 = nn_param.test_data_count - var1 - var2\n",
    "\n",
    "call_dataset_gen(var0,var1,var2,nn_param.train_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Low-res Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/down_scale.py in 2D_data/highres/ref_sph_2D_v02_d000_%03d t 50 factor 9 upres 0 res 150 gui 0 sres 2 out 2D_data/lowres/sph_2D_v02_d000_%03d\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/down_scale.py in 2D_data/highres/ref_sph_2D_v02_d001_%03d t 50 factor 9 upres 0 res 150 gui 0 sres 2 out 2D_data/lowres/sph_2D_v02_d001_%03d\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b4eb854d8007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_d%03d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_%03d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_d%03d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_%03d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrun_manta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scenes/down_scale.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-6304eb351014>\u001b[0m in \u001b[0;36mrun_manta\u001b[0;34m(scene, param, run)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "param['upres'] = data_param.upres\n",
    " \n",
    "param['factor'] = data_param.factor\n",
    "param['gui'] = 0\n",
    "param['t'] = data_param.frame_count\n",
    "\n",
    "for i in range(data_count):\n",
    "    param['in'] = (ref_prefix + \"_d%03d\")%i + \"_%03d\"\n",
    "    param['out'] = (src_prefix + \"_d%03d\")%i + \"_%03d\"\n",
    "    run_manta(\"scenes/down_scale.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Surface-Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/extract_patches.py l_fac 12.0 h_in 2D_data/highres/ref_sph_2D_v02_d000_%03d h_fac 4.0 surface 0.5 t 50 stride 2 h_out 2D_data/patches/highres/ref_sph_2D_v02_d000_%03d l_in 2D_data/lowres/sph_2D_v02_d000_%03d psize 5 l_out 2D_data/patches/lowres/sph_2D_v02_d000_%03d tanh 1 hpsize 15\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/extract_patches.py l_fac 12.0 h_in 2D_data/highres/ref_sph_2D_v02_d001_%03d h_fac 4.0 surface 0.5 t 50 stride 2 h_out 2D_data/patches/highres/ref_sph_2D_v02_d001_%03d l_in 2D_data/lowres/sph_2D_v02_d001_%03d psize 5 l_out 2D_data/patches/lowres/sph_2D_v02_d001_%03d tanh 1 hpsize 15\n",
      "\n",
      "2D_SPH/build/manta 2D_SPH/scenes/extract_patches.py l_fac 12.0 h_in 2D_data/highres/ref_sph_2D_v02_d002_%03d h_fac 4.0 surface 0.5 t 50 stride 2 h_out 2D_data/patches/highres/ref_sph_2D_v02_d002_%03d l_in 2D_data/lowres/sph_2D_v02_d002_%03d psize 5 l_out 2D_data/patches/lowres/sph_2D_v02_d002_%03d tanh 1 hpsize 15\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9804f5f6a8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"h_out\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_patches_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_d%03d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_%03d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"l_out\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_patches_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_d%03d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_%03d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrun_manta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scenes/extract_patches.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-dff3bcb615de>\u001b[0m in \u001b[0;36mrun_manta\u001b[0;34m(scene, param, run)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "src_patches_path = \"%spatches/%s/%s_v%02d\" % (data_loc, src, data_param.prefix, data_version)\n",
    "ref_patches_path = \"%spatches/%s/ref_%s_v%02d\" % (data_loc, ref, data_param.prefix, data_version)\n",
    "\n",
    "#remove_data(src_patches_path)\n",
    "#remove_data(ref_patches_path)\n",
    "\n",
    "param = {}\n",
    "\n",
    "param[\"t\"] = data_param.frame_count\n",
    "\n",
    "# patch size\n",
    "param[\"psize\"] = data_param.patch_size\n",
    "param[\"stride\"] = data_param.stride\n",
    "\n",
    "param[\"hpsize\"] = high_patch_size\n",
    "\n",
    "param[\"l_fac\"] = data_param.l_fac\n",
    "param[\"h_fac\"] = data_param.h_fac\n",
    "param[\"tanh\"] = data_param.use_tanh\n",
    "\n",
    "# tolerance of surface\n",
    "param[\"surface\"] = data_param.surf\n",
    "\n",
    "for i in range(data_count):\n",
    "    param[\"h_in\"] = ref_prefix + \"_d%03d\"%i + \"_%03d\"\n",
    "    param[\"l_in\"] = src_prefix + \"_d%03d\"%i + \"_%03d\"\n",
    "    param[\"h_out\"] = ref_patches_path + \"_d%03d\"%i + \"_%03d\"\n",
    "    param[\"l_out\"] = src_patches_path + \"_d%03d\"%i + \"_%03d\"\n",
    "    run_manta(\"scenes/extract_patches.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show low-res data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py t 50 scr 2D_data/screenshots/20171107/sph_%03d_sdf.png sdf 2D_data/lowres/sph_2D_v02_d004_%03d_sdf.uni in 2D_data/lowres/sph_2D_v02_d004_%03d_ps.uni res 50\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 4\n",
    "\n",
    "# show low res\n",
    "param['in'] = src_prefix + \"_d%03d\"%dataset + \"_%03d_ps.uni\"\n",
    "param['sdf'] = src_prefix + \"_d%03d\"%dataset + \"_%03d_sdf.uni\"\n",
    "param['t'] = data_param.frame_count\n",
    "param['res'] = low_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_%03d_sdf.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show high-res data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py t 50 scr 2D_data/screenshots/20171107/sph_%03d_sdf_ref.png sdf 2D_data/highres/ref_sph_2D_v02_d009_%03d_sdf.uni in 2D_data/highres/ref_sph_2D_v02_d009_%03d_ps.uni res 150\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 9\n",
    "\n",
    "# show high res\n",
    "param['in'] = ref_prefix + \"_d%03d\"%dataset + \"_%03d_ps.uni\"\n",
    "param['sdf'] = ref_prefix + \"_d%03d\"%dataset + \"_%03d_sdf.uni\"\n",
    "param['t'] = data_param.frame_count\n",
    "param['res'] = data_param.res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_%03d_sdf_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show patches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_patches.py psize 5 hpsize 15 ref 2D_data/patches/highres/ref_sph_2D_v02_d000_010_sdf t 1 src 2D_data/patches/lowres/sph_2D_v02_d000_010_sdf vel 2D_data/patches/lowres/sph_2D_v02_d000_010_vel\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "timestep = 10\n",
    "\n",
    "# show patches\n",
    "param['src'] = src_patches_path + \"_d%03d\"%dataset + \"_%03d_sdf\"%timestep\n",
    "param['vel'] = src_patches_path + \"_d%03d\"%dataset + \"_%03d_vel\"%timestep\n",
    "param['ref'] = ref_patches_path + \"_d%03d\"%dataset + \"_%03d_sdf\"%timestep\n",
    "param['psize'] = data_param.patch_size\n",
    "param['hpsize'] = high_patch_size\n",
    "param['t'] = 1#data_param.frame_count\n",
    "\n",
    "#param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_patch_%03d_sdf_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_patches.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_data/patches/lowres/sph_2D_v02_d%03d_%03d\n",
      "2D_data/patches/highres/ref_sph_2D_v02_d%03d_%03d\n",
      "(6510, 5, 5, 4)\n",
      "(6510, 15, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset\n",
    "\n",
    "src_patches_path = \"%spatches/%s/%s_v%02d\" % (data_loc, src, data_param.prefix, data_version) + \"_d%03d\" + \"_%03d\"\n",
    "print(src_patches_path)\n",
    "ref_patches_path = \"%spatches/%s/ref_%s_v%02d\" % (data_loc, ref, data_param.prefix, data_version) + \"_d%03d\" + \"_%03d\"\n",
    "print(ref_patches_path)\n",
    "\n",
    "train_data = Dataset(src_patches_path, ref_patches_path, \n",
    "                     0, nn_param.train_data_count, nn_param.t_start, nn_param.t_end, \n",
    "                     nn_param.features, ['sdf'])\n",
    "test_data = Dataset(src_patches_path, ref_patches_path, \n",
    "                    nn_param.train_data_count, nn_param.train_data_count + nn_param.test_data_count, nn_param.t_start, nn_param.t_end, \n",
    "                    nn_param.features, ['sdf'])\n",
    "\n",
    "print(train_data.data.shape)\n",
    "print(train_data.ref_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_count: 4\n",
      "Use Subpixel Convolution\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras_utils.subpixel import *\n",
    "\n",
    "feature_cnt = train_data.data.shape[3]\n",
    "print(\"feature_count: %d\" % feature_cnt)\n",
    "input_shape = (data_param.patch_size, data_param.patch_size, feature_cnt)\n",
    "output_shape = (high_patch_size, high_patch_size, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=3, kernel_size=3, \n",
    "                              strides=1, input_shape=input_shape, \n",
    "                              activation='tanh', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=3, kernel_size=3,\n",
    "                              strides=1, activation='tanh', padding='same'))\n",
    "#model.add( keras.layers.BatchNormalization() )  \n",
    "\n",
    "model.add(Dense(units=64))\n",
    "model.add(Activation('tanh'))\n",
    "model.add( keras.layers.Dropout(0.5) )  \n",
    "\n",
    "if nn_param.use_spc:\n",
    "    print(\"Use Subpixel Convolution\")\n",
    "    model.add(Subpixel(filters=1, kernel_size=3, r=3,activation='tanh', padding='same'))\n",
    "else:\n",
    "    model.add(keras.layers.Conv2DTranspose(filters=1, kernel_size=3, \n",
    "                                               strides=int(factor_2D), activation='tanh', padding='same'))\n",
    "    model.add(keras.layers.Conv2DTranspose(filters=1, kernel_size=3, \n",
    "                                           strides=1, activation='tanh', padding='same'))\n",
    "\n",
    "model.compile( loss='mse', optimizer=keras.optimizers.adam(lr=nn_param.learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/200 - loss: 0.557732\n",
      "10/200 - loss: 0.297616\n",
      "20/200 - loss: 0.272784\n",
      "30/200 - loss: 0.254519\n",
      "40/200 - loss: 0.245470\n",
      "50/200 - loss: 0.240096\n",
      "60/200 - loss: 0.236626\n",
      "70/200 - loss: 0.232859\n",
      "80/200 - loss: 0.226592\n",
      "90/200 - loss: 0.219319\n",
      "100/200 - loss: 0.215698\n",
      "110/200 - loss: 0.214664\n",
      "120/200 - loss: 0.211153\n",
      "130/200 - loss: 0.200200\n",
      "140/200 - loss: 0.192033\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "class NthLogger(keras.callbacks.Callback):\n",
    "    def __init__(self,n=10):\n",
    "        self.act = 0\n",
    "        self.n = n\n",
    "\n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.act += 1\n",
    "        if self.act % self.n == 0 or self.act == 1:\n",
    "            print('%d/%d - loss: %f val_loss: %f' % (self.act, self.params['epochs'], logs['loss'], logs['val_loss']))\n",
    "            \n",
    "history = model.fit(x=train_data.data,y=train_data.ref_data, validation_split=nn_param.val_split, \n",
    "                    epochs=nn_param.epochs, batch_size=nn_param.batch_size, \n",
    "                    verbose=0, callbacks=[NthLogger()])\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model_path = '%smodel/%s_v%02d_d%02d.h5' % (data_loc, data_param.prefix, data_param.nn_version, data_version)\n",
    "print(\"save model in %s\" % model_path)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/336 [=>............................] - ETA: 0s0.128838796701\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x=test_data.data, y=test_data.ref_data, batch_size=nn_param.batch_size)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from uniio import *\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras_utils.subpixel import *\n",
    "\n",
    "timestep = (nn_param.t_start + nn_param.t_end) // 2\n",
    "\n",
    "model = load_model('%smodel/%s_v%02d_d%02d.h5' % (data_loc, data_param.prefix, data_param.nn_version, data_version), custom_objects={'Subpixel': Subpixel})\n",
    "\n",
    "test_filename = \"%sresult/%s_v%02d\" % (data_loc, data_param.prefix, data_version) + \"_%03d_sdf\" % timestep\n",
    "ref_filename = \"%sresult/ref_%s_v%02d\" % (data_loc, data_param.prefix, data_version) + \"_%03d_sdf\" % timestep\n",
    "result_filename = \"%sresult/result_%s_v%02d\" % (data_loc, data_param.prefix, data_version) + \"_%03d_sdf\" % timestep\n",
    "\n",
    "#remove_data(test_filename)\n",
    "#remove_data(ref_filename)\n",
    "#remove_data(result_filename)\n",
    "\n",
    "result = model.predict(x=test_data.data, batch_size=nn_param.batch_size)\n",
    "\n",
    "for patch in test_data.data:\n",
    "    writeNumpyBuf(test_filename, patch[:,:,0])\n",
    "    \n",
    "for patch in test_data.ref_data:\n",
    "    writeNumpyBuf(ref_filename, patch)\n",
    "    \n",
    "for patch in result:\n",
    "    writeNumpyBuf(result_filename, patch)\n",
    "    \n",
    "finalizeNumpyBufs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_patches.py psize 5 ref2 2D_data/result/ref_sph_2D_v02_010_sdf ref 2D_data/result/result_sph_2D_v02_010_sdf scr 2D_data/screenshots/20171108/sph_patch_%03d_sdf_res.png src 2D_data/result/sph_2D_v02_010_sdf t 1 hpsize 15\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "\n",
    "# show patches\n",
    "param['src'] = test_filename\n",
    "param['ref'] = result_filename\n",
    "param['ref2'] = ref_filename\n",
    "param['psize'] = data_param.patch_size\n",
    "param['hpsize'] = high_patch_size\n",
    "param['t'] = 1\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + \"sph_patch_%03d_sdf_res.png\"\n",
    "\n",
    "run_manta(\"scenes/show_patches.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 152, 1)\n",
      "2D_data/lowres/sph_2D_v02_d004_%03d\n",
      "2D_data/highres/ref_sph_2D_v02_d004_%03d_sdf.uni\n",
      "2D_data/sph_2D_v02_d004_%03d_result.uni\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage.filters as fi\n",
    "\n",
    "def filter2D(kernlen, s, fac):\n",
    "    dirac = np.zeros((kernlen, kernlen))\n",
    "    dirac[kernlen//2, kernlen//2] = 1\n",
    "    return np.clip(fi.gaussian_filter(dirac, s) * fac, a_min=None, a_max=1.0)\n",
    "\n",
    "result = np.ndarray(shape=(data_param.res,data_param.res,1), dtype=float)\n",
    "#weights = np.ndarray(shape=(data_param.res,data_param.res,1), dtype=float)\n",
    "#weights.fill(0)\n",
    "\n",
    "ps = data_param.patch_size//2\n",
    "hps = high_patch_size//2\n",
    "\n",
    "import math\n",
    "border = int(math.ceil(hps-(ps*factor_2D)))\n",
    "\n",
    "result=np.pad(result,((border,border),(border,border),(0,0)),mode=\"edge\")\n",
    "#weights=np.pad(weights,((border,border),(border,border),(0,0)),mode=\"edge\")\n",
    "print(result.shape)\n",
    "dataset = 4#nn_param.train_data_count\n",
    "\n",
    "input_path = src_prefix + \"_d%03d\" % dataset + \"_%03d\"\n",
    "ref_input_path = ref_prefix + \"_d%03d\" % dataset + \"_%03d_sdf.uni\"\n",
    "print(input_path)\n",
    "print(ref_input_path)\n",
    "output_path = \"%s%s_v%02d_d%03d\" % (data_loc, data_param.prefix, data_version, dataset) + \"_%03d_result.uni\"\n",
    "print(output_path)\n",
    "\n",
    "\n",
    "elem_min = np.vectorize(lambda x,y: min(x,y))\n",
    "circular_filter = filter2D(high_patch_size, 3, 500)\n",
    "\n",
    "for t in range(nn_param.t_start, nn_param.t_end):\n",
    "    result.fill(1)\n",
    "    hdr, source = readUni(input_path%t+\"_sdf.uni\")\n",
    "    for f in nn_param.features:\n",
    "        if f != \"sdf\":\n",
    "            _, tmp = readUni(input_path%t+\"_\"+f+\".uni\")\n",
    "            source = np.append(source, tmp, axis=3)\n",
    "\n",
    "    for x in range (ps, low_res-ps, 1):\n",
    "        for y in range(ps, low_res-ps, 1):\n",
    "            if(abs(source[0,x,y,0]) < data_param.surf):\n",
    "                x0=x-ps\n",
    "                x1=x+ps+1\n",
    "                y0=y-ps\n",
    "                y1=y+ps+1\n",
    "                predict = model.predict(x=np.array([source[0,x0:x1,y0:y1]]), batch_size=1)\n",
    "                #if data_param.use_tanh != 0:\n",
    "                    #predict = np.arctanh(predict)\n",
    "                    \n",
    "                predict = predict * circular_filter/data_param.h_fac\n",
    "\n",
    "\n",
    "\n",
    "                x0=int(factor_2D*x)-hps+border\n",
    "                x1=int(factor_2D*x)+hps+border+1\n",
    "                y0=int(factor_2D*y)-hps+border\n",
    "                y1=int(factor_2D*y)+hps+border+1\n",
    "\n",
    "                result[x0:x1,y0:y1,0] = elem_min(result[x0:x1,y0:y1,0], predict[0,:,:,0])\n",
    "\n",
    "    hdr['dimX'] = data_param.res\n",
    "    hdr['dimY'] = data_param.res\n",
    "\n",
    "    #print(result[border:data_param.res+border,border:data_param.res+border,0].shape)\n",
    "    writeUni(output_path%t, hdr, result[border-1:data_param.res+border-1,border-1:data_param.res+border-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show source frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py sdf 2D_data/lowres/sph_2D_v02_d004_%03d_sdf.uni t_end 15 t_start 5 scr 2D_data/screenshots/20171108/sph_2D_v02_d000_%03d_src.png sres 2 res 50\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "scr_path = \"%s_v%02d_d%03d\" % (data_param.prefix, data_version, dataset) + \"_%03d\"\n",
    "\n",
    "# show input\n",
    "param['sdf'] = input_path+\"_sdf.uni\"\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = low_res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + scr_path + \"_src.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show result frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py sdf 2D_data/sph_2D_v02_d004_%03d_result.uni t_end 15 t_start 5 scr 2D_data/screenshots/20171108/sph_2D_v02_d000_%03d_res.png sres 2 res 150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "# show result\n",
    "param['sdf'] = output_path\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + scr_path + \"_res.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show reference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_SPH/build/manta 2D_SPH/scenes/show_particles.py sdf 2D_data/highres/ref_sph_2D_v02_d004_%03d_sdf.uni t_end 15 t_start 5 scr 2D_data/screenshots/20171108/sph_2D_v02_d000_%03d_ref.png sres 2 res 150\n",
      "\n",
      "QThread: Destroyed while thread is still running\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "dataset = 0\n",
    "\n",
    "# show result\n",
    "param['sdf'] = ref_input_path\n",
    "param['t_start'] = nn_param.t_start\n",
    "param['t_end'] = nn_param.t_end\n",
    "param['res'] = data_param.res\n",
    "param['sres'] = data_param.sub_res\n",
    "\n",
    "param['scr'] = create_curr_date_folder(data_loc+'screenshots/') + scr_path + \"_ref.png\"\n",
    "\n",
    "run_manta(\"scenes/show_particles.py\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
